{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1wy8ZYk23IF_tNT-mRaSQrLQkjFRMfnMa","authorship_tag":"ABX9TyMTZUN1ZR7AYYgWzWtoGf+Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","\n","# individual  model\n","model1 = DecisionTreeClassifier()\n","model2 = LogisticRegression(solver='lbfgs', max_iter=1000)\n","model3 = GaussianNB()\n"],"metadata":{"id":"p7iWWafnAO3O","executionInfo":{"status":"ok","timestamp":1677086266972,"user_tz":-330,"elapsed":1032,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_breast_cancer\n","dataset = load_breast_cancer()\n","df = pd.DataFrame(data = dataset.data)\n","df['target'] = dataset.target\n","# X = dataset.iloc[:, 1:31].values\n","# Y = dataset.iloc[:, 31].values\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"fabrDbJ6AapZ","executionInfo":{"status":"ok","timestamp":1677086266973,"user_tz":-330,"elapsed":28,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}},"outputId":"a151bfb7-c8b8-464b-8322-1c765c918630"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         0      1       2       3        4        5        6        7       8  \\\n","0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n","1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n","2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n","3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n","4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n","..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n","564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n","565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n","566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n","567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n","568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n","\n","           9  ...     21      22      23       24       25      26      27  \\\n","0    0.07871  ...  17.33  184.60  2019.0  0.16220  0.66560  0.7119  0.2654   \n","1    0.05667  ...  23.41  158.80  1956.0  0.12380  0.18660  0.2416  0.1860   \n","2    0.05999  ...  25.53  152.50  1709.0  0.14440  0.42450  0.4504  0.2430   \n","3    0.09744  ...  26.50   98.87   567.7  0.20980  0.86630  0.6869  0.2575   \n","4    0.05883  ...  16.67  152.20  1575.0  0.13740  0.20500  0.4000  0.1625   \n","..       ...  ...    ...     ...     ...      ...      ...     ...     ...   \n","564  0.05623  ...  26.40  166.10  2027.0  0.14100  0.21130  0.4107  0.2216   \n","565  0.05533  ...  38.25  155.00  1731.0  0.11660  0.19220  0.3215  0.1628   \n","566  0.05648  ...  34.12  126.70  1124.0  0.11390  0.30940  0.3403  0.1418   \n","567  0.07016  ...  39.42  184.60  1821.0  0.16500  0.86810  0.9387  0.2650   \n","568  0.05884  ...  30.37   59.16   268.6  0.08996  0.06444  0.0000  0.0000   \n","\n","         28       29  target  \n","0    0.4601  0.11890       0  \n","1    0.2750  0.08902       0  \n","2    0.3613  0.08758       0  \n","3    0.6638  0.17300       0  \n","4    0.2364  0.07678       0  \n","..      ...      ...     ...  \n","564  0.2060  0.07115       0  \n","565  0.2572  0.06637       0  \n","566  0.2218  0.07820       0  \n","567  0.4087  0.12400       0  \n","568  0.2871  0.07039       1  \n","\n","[569 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-e1616592-efe5-4f4a-a014-b0af28925401\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>...</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>...</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>...</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>...</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>...</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>21.56</td>\n","      <td>22.39</td>\n","      <td>142.00</td>\n","      <td>1479.0</td>\n","      <td>0.11100</td>\n","      <td>0.11590</td>\n","      <td>0.24390</td>\n","      <td>0.13890</td>\n","      <td>0.1726</td>\n","      <td>0.05623</td>\n","      <td>...</td>\n","      <td>26.40</td>\n","      <td>166.10</td>\n","      <td>2027.0</td>\n","      <td>0.14100</td>\n","      <td>0.21130</td>\n","      <td>0.4107</td>\n","      <td>0.2216</td>\n","      <td>0.2060</td>\n","      <td>0.07115</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>20.13</td>\n","      <td>28.25</td>\n","      <td>131.20</td>\n","      <td>1261.0</td>\n","      <td>0.09780</td>\n","      <td>0.10340</td>\n","      <td>0.14400</td>\n","      <td>0.09791</td>\n","      <td>0.1752</td>\n","      <td>0.05533</td>\n","      <td>...</td>\n","      <td>38.25</td>\n","      <td>155.00</td>\n","      <td>1731.0</td>\n","      <td>0.11660</td>\n","      <td>0.19220</td>\n","      <td>0.3215</td>\n","      <td>0.1628</td>\n","      <td>0.2572</td>\n","      <td>0.06637</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>16.60</td>\n","      <td>28.08</td>\n","      <td>108.30</td>\n","      <td>858.1</td>\n","      <td>0.08455</td>\n","      <td>0.10230</td>\n","      <td>0.09251</td>\n","      <td>0.05302</td>\n","      <td>0.1590</td>\n","      <td>0.05648</td>\n","      <td>...</td>\n","      <td>34.12</td>\n","      <td>126.70</td>\n","      <td>1124.0</td>\n","      <td>0.11390</td>\n","      <td>0.30940</td>\n","      <td>0.3403</td>\n","      <td>0.1418</td>\n","      <td>0.2218</td>\n","      <td>0.07820</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>20.60</td>\n","      <td>29.33</td>\n","      <td>140.10</td>\n","      <td>1265.0</td>\n","      <td>0.11780</td>\n","      <td>0.27700</td>\n","      <td>0.35140</td>\n","      <td>0.15200</td>\n","      <td>0.2397</td>\n","      <td>0.07016</td>\n","      <td>...</td>\n","      <td>39.42</td>\n","      <td>184.60</td>\n","      <td>1821.0</td>\n","      <td>0.16500</td>\n","      <td>0.86810</td>\n","      <td>0.9387</td>\n","      <td>0.2650</td>\n","      <td>0.4087</td>\n","      <td>0.12400</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>7.76</td>\n","      <td>24.54</td>\n","      <td>47.92</td>\n","      <td>181.0</td>\n","      <td>0.05263</td>\n","      <td>0.04362</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.1587</td>\n","      <td>0.05884</td>\n","      <td>...</td>\n","      <td>30.37</td>\n","      <td>59.16</td>\n","      <td>268.6</td>\n","      <td>0.08996</td>\n","      <td>0.06444</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.2871</td>\n","      <td>0.07039</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows Ã— 31 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1616592-efe5-4f4a-a014-b0af28925401')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1616592-efe5-4f4a-a014-b0af28925401 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1616592-efe5-4f4a-a014-b0af28925401');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X = dataset.data\n","y = dataset.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 107,test_size = 0.5)\n","\n","# decision tree \n","model1.fit(X_train, y_train)\n","\n","# logistic regression\n","model2.fit(X_train, y_train)\n","\n","#GausianNB\n","model3.fit(X_train, y_train)\n","\n","model1_pred = model1.predict(X_test)\n","model2_pred = model2.predict(X_test)\n","model3_pred = model3.predict(X_test)\n","type(model1_pred)\n","print(model1_pred)\n","# print(model2_pred)\n","# print(model3_pred)\n","\n","X_blend = np.stack([model1_pred,model2_pred,model3_pred])\n","X_blend = np.transpose(X_blend)  \n","X_blend"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bqMMOBONChvO","executionInfo":{"status":"ok","timestamp":1677086268421,"user_tz":-330,"elapsed":1470,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}},"outputId":"142904d3-e1c9-4cdd-a4df-a73d3c31d32c"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1\n"," 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1\n"," 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n"," 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0\n"," 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0\n"," 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1\n"," 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1\n"," 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 1]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 1, 0],\n","       [0, 0, 0],\n","       [0, 1, 0],\n","       [1, 1, 1],\n","       [0, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 0, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 0, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 0],\n","       [1, 1, 1],\n","       [1, 0, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 0, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 1, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 0, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 0, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 0],\n","       [0, 0, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 0, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [0, 0, 0],\n","       [1, 1, 1],\n","       [1, 1, 1],\n","       [1, 1, 1]])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["model = DecisionTreeClassifier()\n","X_bt, X_out, y_bt,y_out = train_test_split(X_blend,y_test,random_state = 107,test_size = 0.5)\n","model.fit(X_bt,y_bt)\n","y_pred = model.predict(X_blend)\n","\n","from sklearn.metrics import accuracy_score\n","print(\"accuracy\", accuracy_score(y_test,y_pred))\n","\n","from sklearn.metrics import classification_report\n","print(\"precision recall\")\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4Mr0FY2Gayf","executionInfo":{"status":"ok","timestamp":1677086268421,"user_tz":-330,"elapsed":23,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}},"outputId":"f8c337e2-33de-4c75-dc07-20527ed60bb6"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy 0.9543859649122807\n","precision recall\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.94      0.94       106\n","           1       0.97      0.96      0.96       179\n","\n","    accuracy                           0.95       285\n","   macro avg       0.95      0.95      0.95       285\n","weighted avg       0.95      0.95      0.95       285\n","\n"]}]},{"cell_type":"markdown","source":["**Use a LogisticRegression classifier as a blender**"],"metadata":{"id":"h0On0h2dHNsM"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression()\n","# X_btest, X_holdout, y_btest,y_holdout = train_test_split(X_blend,y_test,random_state = 114,test_size = 0.5)\n","model.fit(X_blend,y_test)\n","y_pred = model.predict(X_blend)\n","\n","from sklearn.metrics import accuracy_score\n","print(accuracy_score(y_test,y_pred))\n","\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcrE7UkvHd0m","executionInfo":{"status":"ok","timestamp":1677086268422,"user_tz":-330,"elapsed":11,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}},"outputId":"fc00bda2-398b-4c36-ec8b-c1af577d7d85"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9578947368421052\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.92      0.94       106\n","           1       0.95      0.98      0.97       179\n","\n","    accuracy                           0.96       285\n","   macro avg       0.96      0.95      0.95       285\n","weighted avg       0.96      0.96      0.96       285\n","\n"]}]},{"cell_type":"markdown","source":["**Use StackingClassifier from sklearn to implement the same on cancer dataset.\n","Bagging and RandomForest**"],"metadata":{"id":"kp_Zi3GaHuz_"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.datasets import load_breast_cancer\n","dataset = load_breast_cancer()\n","df = pd.DataFrame(data = dataset.data,columns = dataset.feature_names)\n","df['target'] = dataset.target\n","\n","\n","from sklearn.model_selection import train_test_split\n","X = dataset.data\n","y = dataset.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 107,test_size = 0.3)\n","\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import StackingClassifier\n","estimators = [\n","    ('rf', RandomForestClassifier(n_estimators=10, random_state=107)),\n","    ('bg',BaggingClassifier(n_estimators=10, random_state=107))\n","]\n","clf = StackingClassifier(\n","    estimators=estimators, final_estimator=LogisticRegression()\n",").fit(X_train,y_train)\n","y_pred = clf.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Fe8P3l_H0qO","executionInfo":{"status":"ok","timestamp":1677086287746,"user_tz":-330,"elapsed":1341,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}},"outputId":"4c3ab2b8-65a3-4742-9ae0-0a15cc34449b"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.97      0.95      0.96        62\n","           1       0.97      0.98      0.98       109\n","\n","    accuracy                           0.97       171\n","   macro avg       0.97      0.97      0.97       171\n","weighted avg       0.97      0.97      0.97       171\n","\n"]}]},{"cell_type":"markdown","source":["**Adaboost**"],"metadata":{"id":"Gg4_VaIGIhLc"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.datasets import load_breast_cancer\n","dataset = load_breast_cancer()\n","df = pd.DataFrame(data = dataset.data,columns = dataset.feature_names)\n","df['target'] = dataset.target\n","\n","from sklearn.model_selection import train_test_split\n","X = dataset.data\n","y = dataset.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 107,test_size = 0.3)\n","\n","from sklearn.ensemble import AdaBoostClassifier\n","clf = AdaBoostClassifier(random_state=114).fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rN9j5tpqImhL","executionInfo":{"status":"ok","timestamp":1677086386568,"user_tz":-330,"elapsed":527,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}},"outputId":"f192aa33-b56b-4b47-e0bd-c27b077d704a"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.94      0.94      0.94        62\n","           1       0.96      0.96      0.96       109\n","\n","    accuracy                           0.95       171\n","   macro avg       0.95      0.95      0.95       171\n","weighted avg       0.95      0.95      0.95       171\n","\n"]}]},{"cell_type":"markdown","source":["**Q-4**"],"metadata":{"id":"0-HrT7jAJp6B"}},{"cell_type":"code","source":["from sklearn.ensemble import AdaBoostRegressor\n","import pandas as pd\n","from sklearn.datasets import load_diabetes\n","datasets = load_diabetes()\n","X = datasets.data\n","y = datasets.target\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 107,test_size = 0.3)\n","\n","from sklearn.linear_model import LinearRegression\n","clf = AdaBoostRegressor().fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","\n","print(clf.score(X_test, y_test))\n","\n","from sklearn.metrics import mean_squared_error\n","#mean_squared_error(y_test,y_pred)\n","print(\"mse loss =\", mean_squared_error(y_test,y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tWxnFMeJt2K","executionInfo":{"status":"ok","timestamp":1677086843630,"user_tz":-330,"elapsed":1198,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}},"outputId":"28b5c588-a520-4865-e583-f7475641847e"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["0.421909369557255\n","mse loss = 3677.4699000321043\n"]}]},{"cell_type":"markdown","source":["**Q - 6**"],"metadata":{"id":"KbUTKExXKptd"}},{"cell_type":"code","source":["from sklearn.ensemble import AdaBoostRegressor\n","import pandas as pd\n","datasets = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Contrete.csv\")\n","\n","from sklearn.model_selection import train_test_split\n","X = datasets.iloc[:,:-1].values\n","y = datasets.iloc[:,-1].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 107,test_size = 0.3)\n","\n","from sklearn.linear_model import LinearRegression\n","clf = AdaBoostRegressor().fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","\n","print(clf.score(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Au6ZM1MQKtxg","executionInfo":{"status":"ok","timestamp":1677087183981,"user_tz":-330,"elapsed":445,"user":{"displayName":"CE107_PATEL YASHKUMAR","userId":"09510665966195289271"}},"outputId":"2fce2abf-ecd8-4414-f526-68c73223c8d0"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7935664894343786\n"]}]}]}